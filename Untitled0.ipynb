{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------* FIRST ATTEMPT *---------------------------------------\n",
    "# Problem description: develop a forecasting model that is able to predict several uncorrelated time series\n",
    "\n",
    "# DATA STRUCTURE: \n",
    "# Single folder containing the following files:\n",
    "# -> 'training_data.npy': it contains a numpy array of shape (48000, 2776). 48000 time series of length 2776.\n",
    "# -> 'valid_periods.npy': it contains a numpy array of type (48000, 2) containing for each of the time series the start and end index of the current series, i.e. the part without padding.\n",
    "# -> 'categories.npy': it contains a numpy array of shape (48000,), containing for each of the time series the code of its category. The possible categories are in {'A', 'B', 'C', 'D', 'E', 'F'}.\n",
    "# IMPORTANT: This is a dataset consisting of monovariate time series, i.e. composed of a single feature, belonging to six different domains. The time series of each domain are not to be understood as closely related to each other, but only as collected from similar data sources.\n",
    "# What is required of you is therefore to build a model that is capable of generalising sufficiently to predict the future samples of the 60 time series of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and connect to drive personal folder\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive/My Drive/homework_2/Edoardo\n",
    "\n",
    "# Fix randomness and hide warnings\n",
    "seed = 42\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "\n",
    "import logging\n",
    "\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "# Import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "# Import other support libraries\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=16)\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for data inport:\n",
    "# The function takes as input the path of the folder containing the data and returns the training data, the validation periods and the categories\n",
    "# Before doing so, it eventually unzips it if the zip flag is set to True\n",
    "\n",
    "def import_data(path, zip=False):\n",
    "    if zip:\n",
    "        !unzip -q $path\n",
    "    training_data = np.load('training_data.npy')\n",
    "    valid_periods = np.load('valid_periods.npy')\n",
    "    categories = np.load('categories.npy')\n",
    "    return training_data, valid_periods, categories\n",
    "\n",
    "# Call the function to import the data\n",
    "training_data, valid_periods, categories = import_data('training_dataset.zip', zip=False)\n",
    "\n",
    "# Check the shape of the data\n",
    "print(training_data.shape)\n",
    "print(valid_periods.shape)\n",
    "print(categories.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------* DATA ANALYSIS *---------------------------------------\n",
    "\n",
    "\n",
    "# -<-<-<-<-<-<-<-<-<-< FIRST PLOTS AND PADDING REMOVAL >->->->->->->->->->->-\n",
    "\n",
    "# Plot the first 10 time series\n",
    "\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 10))\n",
    "axs = axs.ravel()\n",
    "for i in range(10):\n",
    "    axs[i].plot(training_data[i])\n",
    "    axs[i].set_title('Category: {}'.format(categories[i]))\n",
    "    axs[i].set_xlabel('Time')\n",
    "    axs[i].set_ylabel('Value')\n",
    "\n",
    "fig.suptitle('First 10 time series', fontsize=16)\n",
    "\n",
    "# Define a function to remove the padding from the time series\n",
    "\n",
    "def remove_padding(data, valid_periods):\n",
    "    data_no_pad = []\n",
    "    for i in range(data.shape[0]):\n",
    "        data_no_pad.append(data[i, valid_periods[i, 0]:valid_periods[i, 1]])\n",
    "    return np.array(data_no_pad)\n",
    "\n",
    "# Remove the padding from the time series\n",
    "training_data_no_pad = remove_padding(training_data, valid_periods)\n",
    "\n",
    "# Plot the first 10 time series without padding\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 10))\n",
    "axs = axs.ravel()\n",
    "for i in range(10):\n",
    "    axs[i].plot(training_data_no_pad[i])\n",
    "    axs[i].set_title('Category: {}'.format(categories[i]))\n",
    "    axs[i].set_xlabel('Time')\n",
    "    axs[i].set_ylabel('Value')\n",
    "\n",
    "fig.suptitle('First 10 time series without padding', fontsize=16)\n",
    "\n",
    "\n",
    "# -<-<-<-<-<-<-<-<-<-< DATA DISTRIBUTION ANALYSIS >->->->->->->->->->->-"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
