{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------* FIRST ATTEMPT *---------------------------------------\n",
    "# Problem description: develop a forecasting model that is able to predict several uncorrelated time series\n",
    "\n",
    "# DATA STRUCTURE: \n",
    "# Single folder containing the following files:\n",
    "# -> 'training_data.npy': it contains a numpy array of shape (48000, 2776). 48000 time series of length 2776.\n",
    "# -> 'valid_periods.npy': it contains a numpy array of type (48000, 2) containing for each of the time series the start and end index of the current series, i.e. the part without padding.\n",
    "# -> 'categories.npy': it contains a numpy array of shape (48000,), containing for each of the time series the code of its category. The possible categories are in {'A', 'B', 'C', 'D', 'E', 'F'}.\n",
    "# IMPORTANT: This is a dataset consisting of monovariate time series, i.e. composed of a single feature, belonging to six different domains. The time series of each domain are not to be understood as closely related to each other, but only as collected from similar data sources.\n",
    "# What is required of you is therefore to build a model that is capable of generalising sufficiently to predict the future samples of the 60 time series of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and connect to drive personal folder\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive/My Drive/homework_2/Edoardo\n",
    "\n",
    "# Fix randomness and hide warnings\n",
    "seed = 42\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "\n",
    "import logging\n",
    "\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "# Import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "# Import other support libraries\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=16)\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for data inport:\n",
    "# The function takes as input the path of the folder containing the data and returns the training data, the validation periods and the categories\n",
    "# Before doing so, it eventually unzips it if the zip flag is set to True\n",
    "\n",
    "def import_data(path, zip=False):\n",
    "    if zip:\n",
    "        !unzip -q $path\n",
    "    training_data = np.load('training_data.npy')\n",
    "    valid_periods = np.load('valid_periods.npy')\n",
    "    categories = np.load('categories.npy')\n",
    "    return training_data, valid_periods, categories\n",
    "\n",
    "# Call the function to import the data\n",
    "training_data, valid_periods, categories = import_data('training_dataset.zip', zip=False)\n",
    "\n",
    "# Check the shape of the data\n",
    "print(training_data.shape)\n",
    "print(valid_periods.shape)\n",
    "print(categories.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------* DATA ANALYSIS *---------------------------------------\n",
    "\n",
    "\n",
    "# -<-<-<-<-<-<-<-<-<-< FIRST PLOTS AND PADDING REMOVAL >->->->->->->->->->->-\n",
    "\n",
    "# Plot the first 10 time series\n",
    "\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 10))\n",
    "axs = axs.ravel()\n",
    "for i in range(10):\n",
    "    axs[i].plot(training_data[i])\n",
    "    axs[i].set_title('Category: {}'.format(categories[i]), frontsize=10)\n",
    "    axs[i].set_xlabel('Time', frontsize=10)\n",
    "    axs[i].set_ylabel('Value', frontsize=10)\n",
    "\n",
    "fig.suptitle('First 10 time series', fontsize=30)\n",
    "\n",
    "# Define a function to remove the padding from the time series\n",
    "\n",
    "def remove_padding(data, valid_periods):\n",
    "    data_no_pad = []\n",
    "    for i in range(data.shape[0]):\n",
    "        data_no_pad.append(data[i, valid_periods[i, 0]:valid_periods[i, 1]])\n",
    "    return np.array(data_no_pad)\n",
    "\n",
    "# Remove the padding from the time series\n",
    "training_data_no_pad = remove_padding(training_data, valid_periods)\n",
    "\n",
    "# Plot the first 10 time series without padding, keeping the information about the orignal temporal location \n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 10))\n",
    "axs = axs.ravel()\n",
    "for i in range(10):\n",
    "    axs[i].plot(range(valid_periods[i, 0], valid_periods[i, 1]), training_data_no_pad[i])\n",
    "    axs[i].set_title('Category: {}'.format(categories[i]), frontsize=10)\n",
    "    axs[i].set_xlabel('Time', frontsize=10)\n",
    "    axs[i].set_ylabel('Value', frontsize=10)\n",
    "\n",
    "fig.suptitle('First 10 time series without padding', fontsize=30)\n",
    "\n",
    "# All this samples belong to category D, and are \"to be understood as not closely related to each other, but only as collected from similar data sources\"\n",
    "# This means that the time seies within the same categoty are to be considered as uncorrelated, but should there not be a correlationbetween the catoegories?\n",
    "# Note that all the values are store as float64, so we can convert them to float32 to save memory\n",
    "print(type(training_data_no_pad[0][0]))\n",
    "training_data = training_data.astype(np.float32)\n",
    "training_data_no_pad = training_data_no_pad.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -<-<-<-<-<-<-<-<-<-< DATA DISTRIBUTION ANALYSIS >->->->->->->->->->->-\n",
    "\n",
    "\n",
    "# GROUP DATA BY CATEGORY:\n",
    "\n",
    "# Transform the categories into numbers\n",
    "categorical_to_numerical = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F':5}\n",
    "\n",
    "for category in np.unique(categories):\n",
    "    categories[categories == category] = categorical_to_numerical[category]\n",
    "# To save memory, convert the categories to int32\n",
    "categories = categories.astype(np.int32)\n",
    "\n",
    "# Now plot the distribution of the time series over the different categories\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.countplot(categories)\n",
    "ax.set_title('Distribution of the time series over the different categories', fontsize=20)\n",
    "ax.set_xlabel('Category')\n",
    "ax.set_ylabel('Number of time series')\n",
    "\n",
    "\n",
    "# -<-<-<-<-<-<-<-<-<-<-<-< DATA NORMLIZATION >->->->->->->->->->->->->-\n",
    "# AS THE DATA HAS ALREADY BEEN NORMALIZED (EACH ROW HAS BEEN NORMALIZED INDIPENDENTLY)\n",
    "# WE DEEMED THIS STEP NOT NECESSARY\n",
    "\n",
    "\n",
    "# Define min_max normalization function\n",
    "def min_max_norm(data, min, max):\n",
    "    return (data - min) / (max - min)\n",
    "\n",
    "# Apply the function over the categories singularly\n",
    "def min_max_norm_by_category(data, categories):\n",
    "    # Loop over the categories\n",
    "    for category in np.unique(categories):\n",
    "        # For each category compute the min and max\n",
    "        C_min = np.min(data[categories == category])\n",
    "        C_max = np.max(data[categories == category])\n",
    "        # Apply the min_max_norm function to the data of the current category\n",
    "        data[categories == category] = min_max_norm(data[categories == category], C_min, C_max)\n",
    "    return data\n",
    "\n",
    "\n",
    "# -<-<-<-<-<-<-< PLOT OF RANDOM TIME SERIES FOR DIFFERENT CATEGORIES >->->->->->-\n",
    "\n",
    "# Plot the first time series for each category\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20, 10))\n",
    "axs = axs.ravel()\n",
    "for i in range(6):\n",
    "    axs[i].plot(training_data_no_pad[categories == i][0])\n",
    "    axs[i].set_title('Category: {}'.format(i), frontsize=10)\n",
    "    axs[i].set_xlabel('Time', frontsize=10)\n",
    "    axs[i].set_ylabel('Value', frontsize=10)\n",
    "\n",
    "fig.suptitle('First time series for each category', fontsize=30)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
